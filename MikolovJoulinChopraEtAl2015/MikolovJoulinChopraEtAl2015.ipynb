{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "\n",
    "# Local Imports\n",
    "sys.path.insert(0, 'python')\n",
    "from lstm import lstm_graph\n",
    "from read_data import read_data\n",
    "from scrn import scrn_graph\n",
    "from srn import srn_graph\n",
    "from tokens import text_elements_to_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Flags\n",
    "rnn_flg = 3      # 1 for SRN\n",
    "                 # 2 for LSTM\n",
    "                 # 3 for SCRN\n",
    "usecase_flg = 1  # 1 for predicting letters\n",
    "                 # 2 for predicting words with fixed vocabulary size\n",
    "                 # 3 for predicting words with cutoff for infrequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Network-specific hyperparameters\n",
    "if rnn_flg == 1:\n",
    "    \n",
    "    # Network hyperparameters\n",
    "    hidden_size = 100         # Dimension of the hidden vector\n",
    "    \n",
    "    # Training hyperparameters\n",
    "    num_unfoldings = 10\n",
    "    \n",
    "elif rnn_flg == 2:\n",
    "    \n",
    "    # Network hyperparameters\n",
    "    hidden_size = 100          # Dimension of the hidden vector\n",
    "    \n",
    "    # Training hyperparameters\n",
    "    num_unfoldings = 10\n",
    "    \n",
    "elif rnn_flg == 3:\n",
    "    \n",
    "    # Network hyperparameters\n",
    "    alpha = 0.95\n",
    "    hidden_size = 100          # Dimension of the hidden vector\n",
    "    state_size = 10            # Dimension of the state vector\n",
    "\n",
    "    # Training hyperparameters\n",
    "    num_unfoldings = 50\n",
    "    \n",
    "# General network hyperparameters\n",
    "vocabulary_size = 10000    # Fixed vocabulary size for usecase_flg = 2\n",
    "word_frequency_cutoff = 5  # Cutoff for infrequent words for usecase_flg = 3\n",
    "\n",
    "# General training hyperparameters\n",
    "batch_size = 32\n",
    "clip_norm = 1.25\n",
    "learning_decay = 1/1.5     # Multiplier to decay the learn rate when required\n",
    "learning_rate = 0.05       # Initial learning rate\n",
    "num_epochs = 100           # Total number of epochs to run the algorithm\n",
    "optimization_frequency = 5 #\n",
    "summary_frequency = 500\n",
    "training_size =  6000000   # Size of training set\n",
    "validation_size = 600000   # Size of validation set\n",
    "\n",
    "# Data file\n",
    "filename = 'data/text8.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare training and validation batches\n",
    "raw_data = read_data(usecase_flg, filename, vocabulary_size)\n",
    "data, dictionary, reverse_dictionary, vocabulary_size = text_elements_to_tokens(usecase_flg, raw_data, vocabulary_size)\n",
    "training_text = data[:training_size]\n",
    "validation_text = data[training_size:training_size+validation_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initiate graph\n",
    "if rnn_flg == 1:\n",
    "    # Use SRN\n",
    "    graph = srn_graph(hidden_size, vocabulary_size, num_unfoldings, batch_size)\n",
    "elif rnn_flg == 2:\n",
    "    # Use LSTM\n",
    "    graph = lstm_graph(hidden_size, vocabulary_size, num_unfoldings, batch_size)\n",
    "elif rnn_flg == 3:\n",
    "    # Use SCRN\n",
    "    graph = scrn_graph(alpha, hidden_size, state_size, vocabulary_size, num_unfoldings, batch_size)\n",
    "    \n",
    "# Optimize graph\n",
    "graph.optimization(learning_rate, learning_decay, optimization_frequency, clip_norm, num_epochs, \n",
    "                   summary_frequency, training_text, validation_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
