<p align="center"><img src="https://latentdotly.files.wordpress.com/2017/04/latently_300.png?w=525&h=525" width="100"></p>

<p align="center"><a href="https://www.ibm.com/blogs/bluemix/2017/07/latently-bitfusion-ibm-cloud-deep-learning/">Latently, Bitfusion, and IBM Cloud enable democratized access to deep learning</a></p>

# Earning the Latently Deep Learning Certificate

## Professional track

To gain access to our cluster of nVidia P100s running on Bitfusion Flex send your resume to dlc@latent.ly. We will set up a Google Hangout and work with you to pick a paper that is suitable for your skill level. 

You can also simply fork the LDLC and implement a paper that we don't yet have an implementation of, or significantly optimize or substantially refactor and improve an existing implementation. Most existing code uses Tensorflow, but other frameworks are acceptable as well. 

## Research track

More advanced candidates may use our our hardware and mentorship resources to conduct original research and to publish it. 

For those who are more business oriented we will work with you to design a novel deep learning architecture using state-of-the-art methods on our GPU cluster.

For those who are more academically oriented you may use our resources on the Comet and Stampede supercomputer (currently #20 in the world) to publish a model built using either [*emergent*](http://grey.colorado.edu/emergent), NEURON, Genesis3, Moose, NEST, PyNN, Brian or Freesurfer. At this time we can only provide mentorship for *emergent*. Note that research done on The Neuroscience Gateway must advance the state of the art in computational neuroscience, computational cognitive neuroscience, cognitive computational neuroscience or a related field. The code will be licensed under the GPLv2 and will not be sold on our marketplace.

# Implementation guidelines

In general it is preferable to replicate a result. This implies reproducing the plots, statistics and results in the paper. Sometimes this isn't possible, in which case the nearest approximate implementation is okay.

Code is subject to code review and should be factored out into reusable modules and functions. Comments are appreciated.

All implementations should have a well-documented README and when possible the code should run in a Jupyter notebook.

Don't look at other existing implementations of your paper, otherwise the author of those implementations may own your code.

# Code ownership

Latently is building a marketplace that allows enterprises to compose implementations into solutions and for all the developers to be compensated. Eventually participants will own their own code and Latently will receive a limited license to it but for now all code is going in the public domain as we build out the certificate program.
